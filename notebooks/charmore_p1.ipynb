{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb31944-f9a1-4db2-9981-fac584632729",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare Dataset\n",
    "import os\n",
    "\n",
    "data_path = '../data/'\n",
    "file_paths = os.listdir(data_path)\n",
    "\n",
    "# List of words\n",
    "S = []\n",
    "\n",
    "def clean_word(word):\n",
    "    return ''.join(filter(str.isalpha, word)).lower().replace(' ', '')\n",
    "\n",
    "for file_path in file_paths:\n",
    "    with open(data_path + file_path, 'r') as file:\n",
    "        words = [ clean_word(word) for word in file.read().splitlines() ]\n",
    "        S.extend(words)\n",
    "        file.close()\n",
    "\n",
    "S = list(sorted(filter(None, set(S))))\n",
    "\n",
    "print(f'total words: {len(S)}')\n",
    "print(f'minimum length: {min(len(w) for w in S)}')\n",
    "print(f'maximum length: {max(len(w) for w in S)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9ae1c2-3d0b-45a5-9ab7-99f755807bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bigrams\n",
    "B = {}\n",
    "for w in S:\n",
    "    chs = list('.' + w + '.')\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        bigram = (ch1, ch2)\n",
    "        B[bigram] = B.get(bigram, 0) + 1\n",
    "\n",
    "sorted(B.items(), key=lambda kv: -kv[1])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2f8016-b4d7-44fe-9904-444835a31a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### encoders and decoders\n",
    "chars = sorted(list(set(''.join(S))))\n",
    "stoi = { s: i + 1 for i, s in enumerate(chars) }\n",
    "stoi['.'] = 0\n",
    "itos = { i: s for s, i in stoi.items() }\n",
    "len(stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147f12b-6299-468d-94a8-cba3fea2249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create tensor to represent bigrams as a matrix\n",
    "import torch\n",
    "\n",
    "N = torch.zeros((48, 48), dtype=torch.int32)\n",
    "\n",
    "for w in S:\n",
    "    chs = list('.' + w + '.')\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881294d1-cdaf-4998-90e2-727c443b196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "N[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fcd1d7-88da-433f-bb77-43909683b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare training set\n",
    "X, Y = [], []\n",
    "\n",
    "for w in S:\n",
    "    chs = list('.' + w + '.')\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        X.append(stoi[ch1])\n",
    "        Y.append(stoi[ch2])\n",
    "        \n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n",
    "n_samples = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4dcbe-c9b7-48d8-afb2-705f0d11f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'inputs: {n_samples}')\n",
    "print(f'targets: {len(Y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba4db1f-c5d4-4bea-a365-6cad536a1011",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Simple neural network with only one layer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# prepare weights for the layer\n",
    "G = torch.Generator().manual_seed(909078)\n",
    "W = torch.randn((48, 48), generator=G, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3355f72-7ec1-4935-999b-b02f0f1fc05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training phase\n",
    "E = 200 # epochs\n",
    "L = 50 # learning rate\n",
    "softening_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f470a-dbcc-465a-a60b-d895b706b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(1, 100 + 1):\n",
    "    # forward pass\n",
    "    xenc = F.one_hot(X, num_classes=48).float()\n",
    "    logits = xenc @ W\n",
    "    # softmax activating\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdim=True)\n",
    "    # negative log likelihood\n",
    "    loss = -probs[torch.arange(n_samples), Y].log().mean() + softening_rate * (W**2).mean()\n",
    "    if e % 10 == 0:\n",
    "        print(f'epoch: {e}, loss: {loss.item()}')\n",
    "    \n",
    "    # backward pass\n",
    "    W.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update weights\n",
    "    W.data += -L * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848a03ca-4dd8-40cd-8e0c-18a323c52710",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the neural net\n",
    "\n",
    "# This seed needs to be changed\n",
    "# if you expect different result\n",
    "seed = 40\n",
    "G = torch.Generator().manual_seed(seed)\n",
    "\n",
    "for _ in range(10):\n",
    "    word = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        xenc = F.one_hot(torch.tensor([i]), num_classes=48).float()\n",
    "        logits = xenc @ W\n",
    "        counts = logits.exp()\n",
    "        prob = counts / counts.sum(1, keepdim=True)\n",
    "\n",
    "        i = torch.multinomial(prob, num_samples=1, replacement=True, generator=G).item()\n",
    "        word.append(itos[i])\n",
    "        if i == 0:\n",
    "            break\n",
    "    word = ''.join(word)\n",
    "    print(f'generated word: {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c17321-811b-4475-8fc2-5c87c959f941",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
